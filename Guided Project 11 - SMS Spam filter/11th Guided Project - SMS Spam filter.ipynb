{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>TITLE:</font> Bayesian Filter for SMS Spam\n",
    "\n",
    "<font color=red>DESCRIPTION</font>\n",
    "\n",
    "This Notebook uses a df of email designated as spam or ham  to learn filtering for future spam messages. The filter was developed as follows:\n",
    "\n",
    "- import df, split into training and test df's\n",
    "- split SMS messages in training df\n",
    "- Create columns for each unique word in the SMS messages\n",
    "- Count the no. of times a particular word is in a message in the training df\n",
    "- Calculate values needed for the Naive Bayes Algorithm\n",
    "- Create a function to remove non words from a SMS message and determine if it's ham or spam\n",
    "- Run function on test df and measure accuracy of ham/spam evaluation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas, read file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\drrdm\\Data Quest Guided Projects\\11th Guided Project - SMS Spam filter\\SMSSpamCollection\", \n",
    "                 header = None, sep = '\\t', names = ['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relative frequency of spam and ham\n",
    "df['Label'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.867925\n",
      "spam    0.132075\n",
      "Name: Label, dtype: float64\n",
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#split data into training and test sets\n",
    "df = df.sample(frac = 1, random_state = 1) #randomize full dataset\n",
    "\n",
    "dftest = df.iloc[0:1113].copy().reset_index(drop = True)\n",
    "dftrain = df.iloc[1114:5572].copy().reset_index(drop = True)\n",
    "\n",
    "print(dftest['Label'].value_counts(normalize = True))\n",
    "print(dftrain['Label'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>NOTE:</font>Distribution of ham and spam in testing and training datasets similiar \n",
    "to distribution in `SMSSpamCollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non word characters from SMS column cells in train dataset\n",
    "\n",
    "dftrain['SMS'] = dftrain['SMS'].str.replace(pat ='\\W', repl = ' ', \n",
    "                                             regex=True).str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split message row into a set of words, then convert into list\n",
    "\n",
    "train_SMSsplit = dftrain['SMS'].str.split()\n",
    "\n",
    "#list of all words in SMS\n",
    "vocabulary = []\n",
    "for row in train_SMSsplit:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "#remove duplicates, convert back to list\n",
    "s = set(vocabulary)\n",
    "vocabulary = list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('eg', 1), ('nookii', 1), ('09061209465', 1), ('pussy', 1), ('db', 1), ('gravel', 1), ('yo', 1), ('mns', 1), ('avoid', 1), ('maintain', 1), ('goldviking', 1), ('exeter', 1), ('jiu', 1), ('ignoring', 1), ('appreciate', 1), ('sticky', 1), ('careers', 1), ('mr', 1), ('mix', 1), ('anything', 1)]\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates in vocabulary\n",
    "import collections\n",
    "counter=collections.Counter(vocabulary)\n",
    "print(counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use code provided by Dataquest to create dictionary of unique words\n",
    "\n",
    "word_counts_per_sms = {unique_word: [0] * len(train_SMSsplit) \n",
    "                       for unique_word in vocabulary}\n",
    "\n",
    "#the above dict comprehension created a dict (words_counts_per_sms) of the unique words for keys and \n",
    "#the associated values are a list of zeros the len of the train df\n",
    "\n",
    "#train_SMSsplit is a Series containing rows of lists which contain the words in the SMS column of the df\n",
    "\n",
    "for index, sms in enumerate(train_SMSsplit): #Loop through rows in the Series, index as counter,sms as Series value \n",
    "    for word in sms:                         #Loop through the words of the list in the Series value (like for i in xxx)\n",
    "        word_counts_per_sms[word][index] += 1 #to index(dict key)[word], list position[index] add 1\n",
    "        \n",
    "#this inner loop will loop through the word list in each row of train_SMSsplit \n",
    "#and if it finds a keyword in word_counts_per_sms it will add 1 to the list[index] value, which started at 0\n",
    "#The outer loop then goes to the next row and the process is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE to self:\n",
    "\n",
    "#what does word_counts_per_sms look like?\n",
    "#firstpair = {k: word_counts_per_sms[k] \n",
    "#               for k in list(word_counts_per_sms)[:1]}\n",
    "\n",
    "#Another way to look at word_counts_per_sms first 2 entries\n",
    "# import itertools\n",
    "# dict(itertools.islice(word_counts_per_sms.items(), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the word_counts_per_SMS into a dataframe\n",
    "train_dict = pd.DataFrame(data = word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat dftrain (label, SMS) with train_dict (individual words in SMS)\n",
    "\n",
    "dftrain_final = pd.concat([dftrain,train_dict], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>eg</th>\n",
       "      <th>nookii</th>\n",
       "      <th>09061209465</th>\n",
       "      <th>pussy</th>\n",
       "      <th>db</th>\n",
       "      <th>gravel</th>\n",
       "      <th>yo</th>\n",
       "      <th>mns</th>\n",
       "      <th>...</th>\n",
       "      <th>loyal</th>\n",
       "      <th>mmmm</th>\n",
       "      <th>barolla</th>\n",
       "      <th>gravity</th>\n",
       "      <th>winds</th>\n",
       "      <th>annoyin</th>\n",
       "      <th>detroit</th>\n",
       "      <th>fromwrk</th>\n",
       "      <th>god</th>\n",
       "      <th>killing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yeah do  don t stand to close tho  you ll catc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 7755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  eg  nookii  \\\n",
       "0   ham  yeah do  don t stand to close tho  you ll catc...   0       0   \n",
       "\n",
       "   09061209465  pussy  db  gravel  yo  mns  ...  loyal  mmmm  barolla  \\\n",
       "0            0      0   0       0   0    0  ...      0     0        0   \n",
       "\n",
       "   gravity  winds  annoyin  detroit  fromwrk  god  killing  \n",
       "0        0      0        0        0        0    0        0  \n",
       "\n",
       "[1 rows x 7755 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I have a train df with ham/spam label for the message, the original SMSmessage, and counts for how often words that showed\n",
    "#up in all the SMS messages were in a particular message\n",
    "dftrain_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recently:  4\n",
      "pin:  5\n",
      "soon:  46\n",
      "to:  1788\n"
     ]
    }
   ],
   "source": [
    "# check randomly chosen words (recently,pin,soon,to) to see if the column count is > 0 (validate this was done right)\n",
    "\n",
    "print('recently: ', dftrain_final['recently'].sum())\n",
    "print('pin: ', dftrain_final['pin'].sum())\n",
    "print('soon: ',dftrain_final['soon'].sum())\n",
    "print('to: ', dftrain_final['to'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "Calculate the values needed for the Bayes filtering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pspam = .1345 #from value counts earlier\n",
    "pham = .8654 #from value counts earlier\n",
    "alpha = 1\n",
    "\n",
    "#of words in the spam and ham messages\n",
    "\n",
    "spam_df = dftrain_final[dftrain_final['Label'] == 'spam'] #boolean index for spam labeled rows\n",
    "spam_no_words = spam_df['SMS'].str.split().apply(len).sum() #split SMS message by words, calculate # of words, sum column \n",
    "\n",
    "ham_df = dftrain_final[dftrain_final['Label'] == 'ham'] #boolean index for ham labeled rows\n",
    "ham_no_words = ham_df['SMS'].str.split().apply(len).sum() #split SMS message by words, calculate # of words, sum column\n",
    "\n",
    "# of vocabulary words\n",
    "\n",
    "no_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dicts of ham and spam words \n",
    "ham_words = {}\n",
    "spam_words = {}\n",
    "for word in vocabulary: #vocabulary is a list of unique words from the SMS column of the df\n",
    "    ham_words[word] = 0 #making a ham dict with all the unique words as keys and value 0\n",
    "    spam_words[word] = 0 #ditto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count word occurences in ham and spam dicts, determine word probability by Bayes Theorem\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_ham_word = ham_df[word].sum() # # of times a word is in the ham df\n",
    " \n",
    " # (n_ham_word + 1) / (total #of words in ham df + # of words in the vocabulary list )\n",
    "    p_ham_word = (n_ham_word + 1)/(ham_no_words + no_vocabulary) \n",
    "\n",
    "    ham_words[word] = p_ham_word # update the ham words dict with the probability of the word being in a ham SMS \n",
    "    \n",
    "# ditto for above with ham\n",
    "    n_spam_word = spam_df[word].sum()\n",
    "    p_spam_word = (n_spam_word + 1)/(spam_no_words + no_vocabulary)\n",
    "    spam_words[word] = p_spam_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eg': 0.0003908285565398645, 'nookii': 8.685079034219212e-05}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check one of the dictionaries to verify\n",
    "#import itertools\n",
    "#dict(itertools.islice(spam_words.items(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of this code provided by Dataquest\n",
    "\n",
    "import re  #import regex\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message) #for message, remove non word characters \n",
    "    message = message.lower() \n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = .1345\n",
    "    p_ham_given_message = .8654\n",
    "    for word in message:\n",
    "        if word in spam_words:\n",
    "            p_spam_given_message *= spam_words[word] #multiply p of getting spam message by p word is in a spam message\n",
    "        if word in ham_words:\n",
    "            p_ham_given_message *= ham_words[word] #ditto\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 4.771573236579387e-25\n",
      "P(Ham|message): 3.4555424517038425e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "#Test the filter on a ham message\n",
    "classify('Sounds good Tom. Then see u there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.2776455587679249e-25\n",
      "P(Ham|message): 2.5841115002039434e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "#Test the filter on a spam message\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run the filter on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = .1345\n",
    "    p_ham_given_message = .8654\n",
    "    for word in message:\n",
    "        if word in spam_words:\n",
    "            p_spam_given_message *= spam_words[word]\n",
    "        if word in ham_words:\n",
    "            p_ham_given_message *= ham_words[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham                       Yep, by the pretty sculpture       ham\n",
       "1   ham      Yes, princess. Are you going to make me moan?       ham\n",
       "2   ham                         Welp apparently he retired       ham\n",
       "3   ham                                            Havent.       ham\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ...       ham"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column showing results of filtering test set\n",
    "\n",
    "dftest['predicted'] = dftest['SMS'].apply(classify_test_set)\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 1100\n",
      "total: 1113\n",
      "accuracy: 98.8%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = dftest.shape[0] #of rows in dftest\n",
    "\n",
    "for row in dftest.iterrows():  #iterows returns tuple of index and the row data as a Series\n",
    "    row = row[1]               #row is the Series (index of Label, SMS, predicted with their values)\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('correct:', correct)\n",
    "print('total:', total)\n",
    "print('accuracy:{0:5.1f}%'.format(correct/total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pleasantly surprised at the accuracy of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
